# -*- coding: utf-8 -*-
"""Copy of homework2_psosm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vOF5kJz5Lodp5PgyTROR2MrpZ1_N4Fif
"""

from google.colab import drive
drive.mount('/content/drive')

#############program to get all retweets###############
import sys
import tweepy
import csv

# Twitter API credentials
consumer_key = 'k1QiJyYepgDNDbYM4iw0v2DcV'
consumer_secret ="M0ULuKySAwAMFUOjGIvPuNsOmcg41wFdYdSB7F4TmGzY6NTGnO"
access_key =  '1359920382401077250-q11sbu6HSQwXfdSAe3U5WFAEvDU2Ja'
access_secret = 'zCfKhHaiFGF3jR0g0qPcemVuP5pkXQuaz7k0rYTrhazPl'

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth,wait_on_rate_limit=True)
id1=[]
id2=[]
tx=[]
tt=[]
non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)
for full_tweets in tweepy.Cursor(api.user_timeline,screen_name='MumbaiPolice',timeout=999999).items(10):
  for tweet in tweepy.Cursor(api.search,q='to:'+'MumbaiPolice',timeout=999999).items(10000):
        id1.append(tweet.id_str)
        id2.append(tweet.in_reply_to_status_id_str)
        tx.append(tweet.text.encode("utf-8").decode("utf-8"))
        tt.append(tweet.created_at)

#########################program to store tweets data#############
with open('MumbaiPolice_withreplyid.csv', 'a') as f:
    csv_writer = csv.DictWriter(f, fieldnames=('id','reply_id', 'text','created_at'))
    csv_writer.writeheader()
    for i in range(len(id1)):
        row = {'id': id1[i], 'reply_id': id2[i],'text': tx[i] 'created_at': tt[i]}
        csv_writer.writerow(row)

#########################
import pandas as pd

# making data frame from csv file
data = pd.read_csv("filename.csv")
print(len(data))  
# sorting by first name
#data.sort_values("First Name", inplace = True)
  
# dropping ALL duplicte values
data=data.drop_duplicates(subset=None, keep='first', inplace=False)
data=data.to_numpy()
# displaying dataata
print(len(data))

############for extracting data##########
import pandas as pd
import tweepy
import csv

consumer_key = 'k1QiJyYepgDNDbYM4iw0v2DcV'
consumer_secret ="M0ULuKySAwAMFUOjGIvPuNsOmcg41wFdYdSB7F4TmGzY6NTGnO"
access_key =  '1359920382401077250-q11sbu6HSQwXfdSAe3U5WFAEvDU2Ja'
access_secret = 'zCfKhHaiFGF3jR0g0qPcemVuP5pkXQuaz7k0rYTrhazPl'
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth,wait_on_rate_limit=True)
user_id = 'MumbaiPolice' 
tw = api.user_timeline(screen_name=user_id, count=200)
all = []
all.extend(tw)
oid = tw[-1].id
while True:
    tw = api.user_timeline(screen_name=user_id, count=200, max_id = oid - 1)
    if len(tw) == 0:
      break
    oid = tw[-1].id
    all.extend(tw)
 tweets = [[tweet.id_str, tweet.in_reply_to_status_id_str, tweet.text.encode("utf-8").decode("utf-8"), tweet.created_at] for i,tweet in enumerate(all)]
df = pd.DataFrame(tweets,columns=["id", "reply id", "text", "created_at"])
df.to_csv('MumbaiPolice_tweets.csv',index=False)

import re
import pandas as pd

rows=[]
data = pd.read_csv("secondnew_MumbaiPolice_tweets.csv")
data=data.drop_duplicates(subset=None, keep='first', inplace=False)
print('total length of data',len(data))  
# sorting by first name
#data.sort_values("First Name", inplace = True)
  
# dropping ALL duplicte values
#data=data.drop_duplicates(subset=None, keep='first', inplace=False)
data=data.to_numpy()

reply=[]

name=[]
for i in data:
  regex = re.compile(r'([A-Z][a-z]+(?: [A-Z][a-z]\.)? [A-Z][a-z]+)')
  nm=regex.findall(i[1])
  #if(len(nm)!=0):
    #print(nm)
    #name.append(nm)
    #reply.append(i[1])

#for i in data:
  #if(i[1]=="@RT"):
    #print(i[0])

mob_no=[]
for i in data:
  #print('new',i[1])
  #x = re.compile('^[0][1-9]{1}[0-9]{9}$')
  #p=x.findall(i[1])
  Pattern = re.compile("(0/91)?[7-9][0-9]{9}")
  p=re.search(Pattern,i[1])
  #print(p)
  if(re.search(Pattern,i[1])):
      #print(p)
      #print(i[1])
      mob_no.append(p)
      if(i[1] not in reply):
        reply.append(i[1])


l_no=[]
for i in data:
  regex = ("^(([A-Z]{2}[0-9]{2})" +
             "( )|([A-Z]{2}-[0-9]" +
             "{2}))((19|20)[0-9]" +
             "[0-9])[0-9]{7}$")
     
    # Compile the ReGex
  p = re.compile(regex)

  if(re.search(p,i[1])):
    l_no.append(i[1])
    if(i[1] not in reply):
        reply.append(i[1])

aa_no=[]
for i in data:
  regex = ("^[2-9]{1}[0-9]{3}\\" +
             "s[0-9]{4}\\s[0-9]{4}$")
     
    # Compile the ReGex
  p = re.compile(regex)

  if(re.search(p,i[1])):
    aa_no.append(i[1])
    if(i[1] not in reply):
        reply.append(i[1])

vehicle_no=[]
for i in data:

  regex = ("^(([A-Z]{2}[0-9]{2})" +
             "( )|([A-Z]{2}-[0-9]" +
             "{2}))((19|20)[0-9]" +
             "[0-9])[0-9]{7}$")
     
  p = re.compile(regex)
  if(re.search(p, i[1])):
      #print(x)
    vehicle_no.append(i[1])
    if(i[1] not in reply):
        reply.append(i[1])

mails=[]
for i in data:
  Pattern = re.compile('^[a-z0-9]+[\._]?[a-z0-9]+[@]\w+[.]\w{2,3}$')
  p=re.search(Pattern,i[1])
  if(re.search(Pattern,i[1])):
    #print(i[1])
    mails.append(i[1])
    if(i[1] not in reply):
      reply.append(i[1])

dob=[]
for i in data:
  #regex = ''\S+@\S+''
  #re.search(regex, email)
  regex = ("^(([A-Z]{2}[0-9]{2})" +
             "( )|([A-Z]{2}-[0-9]" +
             "{2}))((19|20)[0-9]" +
             "[0-9])[0-9]{7}$")
  p = re.compile(regex)
  if(re.search(p, i[1])):
    #print(i[1])
    dob.append(i[1])
    if(i[1] not in reply):
      reply.append(i[1])

print('all pii replies count',len(reply))

pii_media=[]
for i in reply:
  #print(i[1])
  #regex1 = "([^\\s]+(\\.(?i)(jpe?g|png|gif|bmp))$)"
  regex = r"(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+))"
  p = re.compile(regex)
  #p2 = re.compile(regex2)
  if(re.search(p, i)):
    #print('p1',i)
    pii_media.append(i)


all_media=[]
piimedia=[]

for i in data:
  regex = r"(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+))"
  p = re.compile(regex)
  #url = re.findall(regex,i[1])
  #x = re.findall("https", i[1])
  if(re.search(p,i[1])):
    #print(i[1])
    all_media.append(i[1])
    if(re.search("vehicle",i[1]) or re.search("car",i[1]) or re.search("number",i[1]) or re.search("plate",i[1]) or re.search("photo",i[1]) or re.search("id",i[1]) or re.search("no.",i[1])):
      #print(i[1])
      piimedia.append(i[1])

print('name',len(name))
print('mob no',len(mob_no))
print('mails',len(mails))
print('dob',len(dob))
print('PII media',len(pii_media))
print('all media',len(all_media))
#print(aa_no)
print('vehicle no',len(vehicle_no))
print('license',len(l_no))
print('AAdhar no',len(aa_no))
print('finding mentioned pii medias',len(piimedia))

c=0 
report=[]    
for i in data:
  if(re.search('report',i[1])):
    c+=1
    report.append(i[1])
    #print(c,i[1])
print(c)

c=0 
request=[]    
for i in data:
  if(re.search('request',i[1])):
    c+=1
    request.append(i[1])
    #print(c,i[1])
print(c)

c=0 
appreciation=[]    
for i in data:
  if(re.search('appreciation',i[1]) or re.search('Thank you',i[1]) or re.search('thank you',i[1])):
    c+=1
    appreciation.append(i[1])
    #print(c,i[1])
print(c)

c=0 
accountability=[]    
for i in data:
  if(re.search('responsible',i[1])):
    c+=1
    accountability.append(i[1])
    #print(c,i[1])
print(c)

################code for getting data of hashtag################
import tweepy

import sys
import csv

# Twitter API credentials
consumer_key = 'k1QiJyYepgDNDbYM4iw0v2DcV'
consumer_secret ="M0ULuKySAwAMFUOjGIvPuNsOmcg41wFdYdSB7F4TmGzY6NTGnO"
access_key =  '1359920382401077250-q11sbu6HSQwXfdSAe3U5WFAEvDU2Ja'
access_secret = 'zCfKhHaiFGF3jR0g0qPcemVuP5pkXQuaz7k0rYTrhazPl'

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth)

#tag =str(input("Please enter your hashtag text:"))
user_id=[]
tweets_list=[] 
likes=[]
retweet_count=[]
search_tag="#CSKvRR"
tweets = tweepy.Cursor(api.search,q=search_tag,).items(10000)
for tweet in tweets:
      user_id.append(tweet.id_str)
      tweets_list.append(tweet.text.encode("utf-8").decode("utf-8"))
      likes.append(tweet.favorite_count)
      retweet_count.append(tweet.retweet_count)

#########################program to store hashtag data#############
with open('CSKvRR.csv', 'a') as f:
    csv_writer = csv.DictWriter(f, fieldnames=('user', 'text','favorite_count', 'retweet_count'))
    csv_writer.writeheader()
    for i in range(len(user_id)):
        #print(replies[i])
        row = {'user': user_id[i], 'text': tweets_list[i], 'favorite_count':likes[i], 'retweet_count':retweet_count[i]}
        csv_writer.writerow(row)

#sec-2 question-1 part a
#most number of occurrences

print('most occurence of respective hashtags in tweet')
import pandas as pd
data = pd.read_csv("Aunt Polly.csv")
data=data.to_numpy()
max0=0
for i in data:
  c=i[1].count("Aunt Polly")
  if(c>max0):
    max0=c
  #print(i[1])
print(max0)

data = pd.read_csv("CSKvPBKS.csv")
data=data.to_numpy()
max1=0
for i in data:
  c=i[1].count("CSKvPBKS")
  if(c>max1):
    max1=c
  #print(i[1])
print(max1)

data = pd.read_csv("EVETOT.csv")
data=data.to_numpy()
max2=0
for i in data:
  c=i[1].count("EVETOT")
  if(c>max2):
    max2=c
  #print(i[1])
print(max2)

data = pd.read_csv("Everton.csv")
data=data.to_numpy()
max3=0
for i in data:
  c=i[1].count("Everton")
  if(c>max3):
    max3=c
  #print(i[1])
print(max3)

data = pd.read_csv("GetWellSoonJANASENANI.csv")
data=data.to_numpy()
max4=0
for i in data:
  c=i[1].count("GetWellSoonJANASENANI")
  if(c>max4):
    max4=c
  #print(i[1])
print(max4)

data = pd.read_csv("HBDChiyaanVikram.csv")
data=data.to_numpy()
max5=0
for i in data:
  c=i[1].count("HBDChiyaanVikram")
  if(c>max5):
    max5=c
  #print(i[1])
print(max5)

data = pd.read_csv("Harry Kane.csv")
data=data.to_numpy()
max6=0
for i in data:
  c=i[1].count("Harry Kane")
  if(c>max6):
    max6=c
  #print(i[1])
print(max6)

data = pd.read_csv("HelenMcCrory.csv")
data=data.to_numpy()
max7=0
for i in data:
  c=i[1].count("HelenMcCrory")
  if(c>max7):
    max7=c
  #print(i[1])
print(max7)

data = pd.read_csv("Meredith.csv")
data=data.to_numpy()
max8=0
for i in data:
  c=i[1].count("Meredith")
  if(c>max8):
    max8=c
  #print(i[1])
print(max8)

data = pd.read_csv("WhistlePodu.csv")
data=data.to_numpy()
max9=0
for i in data:
  c=i[1].count("WhistlePodu")
  if(c>max9):
    max9=c
  #print(i[1])
print(max9)

data = pd.read_csv("Yellove.csv")
data=data.to_numpy()
max10=0
for i in data:
  c=i[1].count("Yellove")
  if(c>max10):
    max10=c
  #print(i[1])
print(max10)

#sec-2 question-1 part b
#most number of likes per hashtag

import pandas as pd
data = pd.read_csv("Aunt Polly.csv")
data=data.to_numpy()
max0=0
for i in data:
  c=i[2]
  if(c>max0):
    max0=c
  #print(i[1])
print(max0)

data = pd.read_csv("CSKvPBKS.csv")
data=data.to_numpy()
max1=0
for i in data:
  c=i[2]
  if(c>max1):
    max1=c
  #print(i[1])
print(max1)

data = pd.read_csv("EVETOT.csv")
data=data.to_numpy()
max2=0
for i in data:
  c=i[2]
  if(c>max2):
    max2=c
  #print(i[1])
print(max2)

data = pd.read_csv("Everton.csv")
data=data.to_numpy()
max3=0
for i in data:
  c=i[2]
  if(c>max3):
    max3=c
  #print(i[1])
print(max3)

data = pd.read_csv("GetWellSoonJANASENANI.csv")
data=data.to_numpy()
max4=0
for i in data:
  c=i[2]
  if(c>max4):
    max4=c
  #print(i[1])
print(max4)

data = pd.read_csv("HBDChiyaanVikram.csv")
data=data.to_numpy()
max5=0
for i in data:
  c=i[2]
  if(c>max5):
    max5=c
  #print(i[1])
print(max5)

data = pd.read_csv("Harry Kane.csv")
data=data.to_numpy()
max6=0
for i in data:
  c=i[2]
  if(c>max6):
    max6=c
  #print(i[1])
print(max6)

data = pd.read_csv("HelenMcCrory.csv")
data=data.to_numpy()
max7=0
for i in data:
  c=i[2]
  if(c>max7):
    max7=c
  #print(i[1])
print(max7)

data = pd.read_csv("Meredith.csv")
data=data.to_numpy()
max8=0
for i in data:
  c=i[2]
  if(c>max8):
    max8=c
  #print(i[1])
print(max8)

data = pd.read_csv("WhistlePodu.csv")
data=data.to_numpy()
max9=0
for i in data:
  c=i[2]
  if(c>max9):
    max9=c
  #print(i[1])
print(max9)

data = pd.read_csv("Yellove.csv")
data=data.to_numpy()
max10=0
for i in data:
  c=i[2]
  if(c>max10):
    max10=c
  #print(i[1])
print(max10)

#sec-2 question-1 part c
#most number of retweets per hashtag

import pandas as pd
data = pd.read_csv("Aunt Polly.csv")
data=data.to_numpy()
max0=0
for i in data:
  c=i[3]
  if(c>max0):
    max0=c
  #print(i[1])
print(max0)

data = pd.read_csv("CSKvPBKS.csv")
data=data.to_numpy()
max1=0
for i in data:
  c=i[3]
  if(c>max1):
    max1=c
  #print(i[1])
print(max1)

data = pd.read_csv("EVETOT.csv")
data=data.to_numpy()
max2=0
for i in data:
  c=i[3]
  if(c>max2):
    max2=c
  #print(i[1])
print(max2)

data = pd.read_csv("Everton.csv")
data=data.to_numpy()
max3=0
for i in data:
  c=i[3]
  if(c>max3):
    max3=c
  #print(i[1])
print(max3)

data = pd.read_csv("GetWellSoonJANASENANI.csv")
data=data.to_numpy()
max4=0
for i in data:
  c=i[3]
  if(c>max4):
    max4=c
  #print(i[1])
print(max4)

data = pd.read_csv("HBDChiyaanVikram.csv")
data=data.to_numpy()
max5=0
for i in data:
  c=i[3]
  if(c>max5):
    max5=c
  #print(i[1])
print(max5)

data = pd.read_csv("Harry Kane.csv")
data=data.to_numpy()
max6=0
for i in data:
  c=i[3]
  if(c>max6):
    max6=c
  #print(i[1])
print(max6)

data = pd.read_csv("HelenMcCrory.csv")
data=data.to_numpy()
max7=0
for i in data:
  c=i[3]
  if(c>max7):
    max7=c
  #print(i[1])
print(max7)

data = pd.read_csv("Meredith.csv")
data=data.to_numpy()
max8=0
for i in data:
  c=i[3]
  if(c>max8):
    max8=c
  #print(i[1])
print(max8)

data = pd.read_csv("WhistlePodu.csv")
data=data.to_numpy()
max9=0
for i in data:
  c=i[3]
  if(c>max9):
    max9=c
  #print(i[1])
print(max9)

data = pd.read_csv("Yellove.csv")
data=data.to_numpy()
max10=0
for i in data:
  c=i[3]
  if(c>max10):
    max10=c
  #print(i[1])
print(max10)

#sec-2 question-1 inference

import pandas as pd
data = pd.read_csv("Meredith.csv")
data=data.to_numpy()
min=0
for i in data:
  c=i[1].count("Meredith")
  if(c<min):
    min=c
  #print(i[1])
print(min)

import tweepy
import csv
import pandas as pd
import math
import numpy as np
import re
data = pd.read_csv("MumbaiPolice_withreplyid.csv")
data=data.drop_duplicates(subset=None, keep='first', inplace=False)
data=data.to_numpy()
data=data.tolist()
print(len(data))

# Twitter API credentials
consumer_key = 'k1QiJyYepgDNDbYM4iw0v2DcV'
consumer_secret ="M0ULuKySAwAMFUOjGIvPuNsOmcg41wFdYdSB7F4TmGzY6NTGnO"
access_key =  '1359920382401077250-q11sbu6HSQwXfdSAe3U5WFAEvDU2Ja'
access_secret = 'zCfKhHaiFGF3jR0g0qPcemVuP5pkXQuaz7k0rYTrhazPl'

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth)


fid=[]
sid=[]
tid=[]
fcr=[]
scr=[]
ftx=[]
stx=[]
final=[]

for i in data:
  if not math.isnan(i[1]):
    try:
      #print(i[0],int(i[1]))
      fid.append(i[0])
      sid.append(i[1])
      ftx.append(i[2])
      fcr.append(i[3])
      tweet=api.get_status(int(i[1]))
      tid.append(tweet.id_str)
      stx.append(tweet.text.encode("utf-8").decode("utf-8"))
      scr.append(tweet.created_at)
      fl=[i[0],int(i[1]),i[3],tweet.created_at]
      final.append(list(fl))
    except tweepy.TweepError as te:

      val=0
    

#print(ndata[0])

from datetime import datetime
from statistics import stdev,mean


df = pd.DataFrame(final,columns=["id-1", "id-2", "created_at-1", "created_at-2"])
df=df.to_numpy()
df=df.tolist()
time=[]
t1=[]
t2=[]

for i in df:
  t1.append(datetime.strptime(str(i[2]), '%Y-%m-%d %H:%M:%S'))
for i in df:
  t2.append(datetime.strptime(str(i[3]), '%Y-%m-%d %H:%M:%S'))

for i in range(len(t1)):
    t=t1[i]-t2[i]
    t=round(t.total_seconds()/60)
    time.append(t)
    

print("Maximum of response time",max(time))
print("Minimum of response time",min(time))
print("Mean of response time",mean(time))
print("Standard devaition of response time",stdev(time))

import plotly.graph_objects as go
id=[]
for i in df:
  id.append(i[0])
figure = go.Figure([go.Scatter(x=id, y=time)])
figure.show()